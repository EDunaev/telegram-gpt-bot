#!/usr/bin/env python3
import os
import tempfile
import requests
import logging
import os
import requests
from dotenv import load_dotenv
from pydub import AudioSegment
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)
from telegram.ext.filters import Document
from collections import defaultdict, deque
from telegram.ext import CommandHandler

# –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ø–æ–∑–∂–µ
TELEGRAM_TOKEN = None
OPENAI_API_KEY = None
DEFAULT_MODEL = None
GOOGLE_CSE_API_KEY = None
GOOGLE_CSE_CX = None
client = None
current_model = None
user_histories = {}

ADMINS = {1091992386, 1687504544} 
LIMITED_USERS = {111111111, 222222222, 333333333} 
CHAT_ID = -1001785925671
BOT_USERNAME = "DunaevAssistentBot"
chat_history = defaultdict(lambda: deque(maxlen=100))

logging.basicConfig(
    filename="bot.log",
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

# üîá –û—Ç–∫–ª—é—á–∞–µ–º –ª–∏—à–Ω–∏–µ –ª–æ–≥–∏ –æ—Ç —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("telegram.bot").setLevel(logging.INFO)
logging.getLogger("telegram.ext._application").setLevel(logging.WARNING)
logging.getLogger("telegram.ext._updater").setLevel(logging.WARNING)
logging.getLogger("telegram.request").setLevel(logging.INFO)

# --------------------
# Helpers
# --------------------
def init_env():
    global TELEGRAM_TOKEN, OPENAI_API_KEY, DEFAULT_MODEL, GOOGLE_CSE_API_KEY, GOOGLE_CSE_CX, client, current_model
    
    # --------------------
    # Env & clients
    # --------------------
    load_dotenv()
    TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    DEFAULT_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo") 
    GOOGLE_CSE_API_KEY = os.getenv("GOOGLE_CSE_API_KEY")
    GOOGLE_CSE_CX = os.getenv("GOOGLE_CSE_CX")

    if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
        raise RuntimeError("TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω—ã –≤ .env")

    from openai import OpenAI
    client = OpenAI(api_key=OPENAI_API_KEY)
    current_model = DEFAULT_MODEL

def format_exc(e: Exception) -> str:
    return f"{type(e).__name__}: {e}"

def is_admin(user_id: int) -> bool:
    return user_id in ADMINS

def is_allowed(update: Update) -> bool:
    user_id = update.effective_user.id
    chat = update.effective_chat
    message = update.message

    text = message.text or message.caption or ""
    logging.info(f"[{user_id}] - chat_id: {chat.id} - type: {chat.type} - Text: {text}")
 # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –∞–¥–º–∏–Ω, –≤—Å–µ–≥–¥–∞ —Ä–∞–∑—Ä–µ—à–∞–µ–º
    if chat.type == "private" and user_id in ADMINS:
        return True

    if chat.id == CHAT_ID and chat.type in ("group", "supergroup"):
        # 1. –£–ø–æ–º–∏–Ω–∞–Ω–∏–µ
        if BOT_USERNAME.lower() in text.lower():
            return True
        # 2. –û—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞
        if message.reply_to_message and message.reply_to_message.from_user.username == BOT_USERNAME:
            return True
    
    return False

def google_search(query: str, num_results: int = 5):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ Google —Å –ø–æ–º–æ—â—å—é Custom Search API.
    
    :param query: —Å—Ç—Ä–æ–∫–∞ –ø–æ–∏—Å–∫–∞
    :param num_results: —Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–µ—Ä–Ω—É—Ç—å (1-10)
    :return: —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ "–ó–∞–≥–æ–ª–æ–≤–æ–∫ - –°—Å—ã–ª–∫–∞"
    """
    if not GOOGLE_CSE_API_KEY or not GOOGLE_CSE_CX:
        raise RuntimeError("Google API –∫–ª—é—á –∏–ª–∏ CX –Ω–µ –∑–∞–¥–∞–Ω—ã –≤ .env")

    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "key": GOOGLE_CSE_API_KEY,
        "cx": GOOGLE_CSE_CX,
        "q": query,
        "num": num_results
    }

    resp = requests.get(url, params=params, timeout=10)
    resp.raise_for_status()
    data = resp.json()

    results = []
    for item in data.get("items", []):
        title = item.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
        link = item.get("link", "")
        snippet = item.get("snippet", "")
        results.append(f"{title}\n{snippet}\n{link}")

    return results
# --------------------
# Handlers
# --------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user_id = update.effective_user.id
    base = "–ü—Ä–∏–≤–µ—Ç! –Ø Telegram-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç–µ–∫—Å—Ç–∞ –∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.\n\n"
    common_cmds = "–ö–æ–º–∞–Ω–¥—ã:\n/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n/help ‚Äî –ø–æ–º–æ—â—å"
    if is_admin(user_id):
        extra = "\n/model <name> ‚Äî —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å\n/quota ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ—Å—Ç–∞—Ç–æ–∫ –±—é–¥–∂–µ—Ç–∞ OpenAI API"
        await update.message.reply_text(base + common_cmds + extra)
    else:
        await update.message.reply_text(base + common_cmds)

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
         return
    user_id = update.effective_user.id
    base = "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n/help ‚Äî –ø–æ–º–æ—â—å"
    if is_admin(user_id):
        extra = "\n/model <name> ‚Äî —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å\n/quota ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ—Å—Ç–∞—Ç–æ–∫ –±—é–¥–∂–µ—Ç–∞ OpenAI API"
        await update.message.reply_text(base + extra)
    else:
        await update.message.reply_text(base)

async def set_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user_id = update.effective_user.id
    if not is_admin(user_id):
        await update.message.reply_text("üö´ –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —Å–º–µ–Ω—É –º–æ–¥–µ–ª–∏.")
        return
    
    global current_model
    if not context.args:
        await update.message.reply_text(
            f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {current_model}\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /model gpt-4o –∏–ª–∏ /model gpt-3.5-turbo"
        )
        return
    new_model = context.args[0].strip()
    current_model = new_model
    await update.message.reply_text(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {current_model}")

async def quota(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user_id = update.effective_user.id
    if not is_admin(user_id):
        await update.message.reply_text("üö´ –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —Å–º–µ–Ω—É –º–æ–¥–µ–ª–∏.")
        return
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Å—Ç–∞—Ç–æ–∫ —Å—Ä–µ–¥—Å—Ç–≤ –ø–æ API. –ú–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤."""
    try:
        headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
        r = requests.get(
            "https://api.openai.com/dashboard/billing/credit_grants",
            headers=headers,
            timeout=10,
        )
        if r.status_code != 200:
            await update.message.reply_text(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–≤–æ—Ç—É (HTTP {r.status_code}): {r.text}"
            )
            return
        data = r.json()
        total = data.get("total_granted", 0.0)
        used = data.get("total_used", 0.0)
        remaining = data.get("total_available", 0.0)
        await update.message.reply_text(
            f"üí∞ –ë–∞–ª–∞–Ω—Å OpenAI API:\n"
            f"‚Äî –í—ã–¥–∞–Ω–æ: ${total:.2f}\n"
            f"‚Äî –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: ${used:.2f}\n"
            f"‚Äî –û—Å—Ç–∞—Ç–æ–∫: ${remaining:.2f}"
        )
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–≤–æ—Ç—ã: {format_exc(e)}")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    message = update.message
    chat = update.effective_chat
    user_input = message.text or ""
    user_input = user_input.replace(f"@{BOT_USERNAME}", "").strip()
    user = update.effective_user
    user_id = user.id

    messages = []

    # üí¨ –ï—Å–ª–∏ —ç—Ç–æ reply –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞ —Å —Ç–µ–∫—Å—Ç–æ–º ‚Äî –¥–æ–±–∞–≤–∏–º –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if chat.type in ("group", "supergroup") and message.reply_to_message:
        reply_msg = message.reply_to_message
        if reply_msg.from_user and reply_msg.from_user.username == BOT_USERNAME:
            prev_text = reply_msg.text or ""
            if prev_text:
                messages.append({"role": "user", "content": prev_text})
    
    if chat.type == "private":
        if user_id not in user_histories:
            user_histories[user_id] = []
        messages = user_histories[user_id]
        messages.append({"role": "user", "content": user_input})
        
    messages.append({"role": "user", "content": user_input})

    logging.info(f"[{user.id}] @{user.username or 'no_username'} - TEXT: {user_input}")
    try:
        resp = client.chat.completions.create(
            model=current_model,
            messages=messages,
        )
        await message.reply_text(resp.choices[0].message.content)
    except Exception as e:
        await message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {format_exc(e)}")

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user = update.effective_user
    logging.info(f"[{user.id}] @{user.username or 'no_username'} - VOICE: –ø–æ–ª—É—á–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
    try:
        voice_file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as f:
            await voice_file.download_to_drive(f.name)
            ogg_path = f.name

        wav_path = ogg_path.replace(".ogg", ".wav")
        AudioSegment.from_ogg(ogg_path).export(wav_path, format="wav")

        # –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å (Whisper)
        with open(wav_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
            )
        text = transcript.text
        logging.info(f"{user} - VOICE TEXT: {text}")

        # –û—Ç–≤–µ—á–∞–µ–º LLM-–æ–º
        resp = client.chat.completions.create(
            model=current_model,
            messages=[{"role": "user", "content": text}],
        )
        await update.message.reply_text(
            f"üó£Ô∏è –¢—ã —Å–∫–∞–∑–∞–ª: {text}\n\nü§ñ {resp.choices[0].message.content}"
        )
    except Exception as e:
        logging.error(f"{user} - VOICE ERROR: {str(e)}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ: {format_exc(e)}")

async def handle_unsupported(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user = update.effective_user
    kind = type(update.message.effective_attachment)
    caption = update.message.caption or "(–±–µ–∑ –ø–æ–¥–ø–∏—Å–∏)"

    logging.info(f"[{user.id}] @{user.username or 'no_username'} - UNSUPPORTED: {kind} - Caption: {caption}")
    await update.message.reply_text("‚ùå –ò–∑–≤–∏–Ω–∏—Ç–µ, —è –ø–æ–∫–∞ –Ω–µ —É–º–µ—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ñ–∞–π–ª—ã, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤–ª–æ–∂–µ–Ω–∏—è.")

async def search_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args:
        await update.message.reply_text("‚ö†Ô∏è –£–∫–∞–∂–∏ –∑–∞–ø—Ä–æ—Å: /search <—Ç–µ–∫—Å—Ç>")
        return
    
    query = " ".join(context.args)
    try:
        results = google_search(query)
        if not results:
            await update.message.reply_text("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            return
        
        reply_text = "\n\n".join(results)
        await update.message.reply_text(reply_text)
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")

async def debug_log(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        logging.info("RAW UPDATE: %s", update.to_dict())
    except Exception as e:
        logging.exception("Failed to log raw update: %s", e)

async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if update.effective_chat.type == "private":
        user_histories.pop(user_id, None)
        await update.message.reply_text("üßπ –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω.")

# --------------------
# Main
# --------------------
def main():
    init_env()
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    # –ö–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("model", set_model))
    app.add_handler(CommandHandler("quota", quota))
    app.add_handler(CommandHandler("reset", reset))
    app.add_handler(CommandHandler("search", search_cmd))

    # –°–æ–æ–±—â–µ–Ω–∏—è
    #app.add_handler(MessageHandler(filters.ALL, debug_log), group=0)
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.PHOTO | Document.ALL | filters.VIDEO, handle_unsupported))

 

    logging.info(f"GPT-–±–æ—Ç –∑–∞–ø—É—â–µ–Ω! –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {current_model}")
    app.run_polling()
    me = app.bot.get_me()
    logging.info("Bot username:", me.username)

if __name__ == "__main__":
    main()
