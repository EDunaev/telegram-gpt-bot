#!/usr/bin/env python3
import os
import tempfile
import requests
import logging
import os
import requests
from dotenv import load_dotenv
from pydub import AudioSegment
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)
from telegram.ext.filters import Document
from collections import defaultdict, deque
from telegram.ext import CommandHandler
from typing import List

# –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ø–æ–∑–∂–µ
TELEGRAM_TOKEN = None
OPENAI_API_KEY = None
DEFAULT_MODEL = None
GOOGLE_CSE_API_KEY = None
GOOGLE_CSE_CX = None
client = None
current_model = None
user_histories = {}

ADMINS = {1091992386, 1687504544} 
LIMITED_USERS = {111111111, 222222222, 333333333} 
CHAT_ID = -1001785925671
BOT_USERNAME = "DunaevAssistentBot"
chat_history = defaultdict(lambda: deque(maxlen=100))

logging.basicConfig(
    filename="bot.log",
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

# üîá –û—Ç–∫–ª—é—á–∞–µ–º –ª–∏—à–Ω–∏–µ –ª–æ–≥–∏ –æ—Ç —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("telegram.bot").setLevel(logging.INFO)
logging.getLogger("telegram.ext._application").setLevel(logging.WARNING)
logging.getLogger("telegram.ext._updater").setLevel(logging.WARNING)
logging.getLogger("telegram.request").setLevel(logging.INFO)

# --------------------
# Helpers
# --------------------
def init_env():
    global TELEGRAM_TOKEN, OPENAI_API_KEY, DEFAULT_MODEL, GOOGLE_CSE_API_KEY, GOOGLE_CSE_CX, client, current_model
    
    # --------------------
    # Env & clients
    # --------------------
    load_dotenv()
    TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    DEFAULT_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo") 
    GOOGLE_CSE_API_KEY = os.getenv("GOOGLE_CSE_API_KEY")
    GOOGLE_CSE_CX = os.getenv("GOOGLE_CSE_CX")

    if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
        raise RuntimeError("TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω—ã –≤ .env")

    from openai import OpenAI
    client = OpenAI(api_key=OPENAI_API_KEY)
    current_model = DEFAULT_MODEL

def format_exc(e: Exception) -> str:
    return f"{type(e).__name__}: {e}"

def is_admin(user_id: int) -> bool:
    return user_id in ADMINS

def is_allowed(update: Update) -> bool:
    user_id = update.effective_user.id
    chat = update.effective_chat
    message = update.message

    text = message.text or message.caption or ""
    logging.info(f"[{user_id}] - chat_id: {chat.id} - type: {chat.type} - Text: {text}")
 # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ‚Äî –∞–¥–º–∏–Ω, –≤—Å–µ–≥–¥–∞ —Ä–∞–∑—Ä–µ—à–∞–µ–º
    if chat.type == "private" and user_id in ADMINS:
        return True

    if chat.id == CHAT_ID and chat.type in ("group", "supergroup"):
        # 1. –£–ø–æ–º–∏–Ω–∞–Ω–∏–µ
        if BOT_USERNAME.lower() in text.lower():
            return True
        # 2. –û—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞
        if message.reply_to_message and message.reply_to_message.from_user.username == BOT_USERNAME:
            return True
    
    return False

def should_web_search(user_input: str) -> bool:
    """
    –ë—ã—Å—Ç—Ä—ã–π –∏ –¥–µ—à—ë–≤—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –Ω–∞–º–µ—Ä–µ–Ω–∏—è –∏–¥—Ç–∏ –≤ –≤–µ–±:
    1) –ñ—ë—Å—Ç–∫–∏–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (–Ω–∞–¥—ë–∂–Ω–æ, 0$)
    2) (–æ–ø—Ü.) LLM-–¥–µ—Ç–µ–∫—Ç–æ—Ä ‚Äî —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –±–ª–æ–∫ –Ω–∏–∂–µ
    """
    kw = [
        "–Ω–æ–≤–æ—Å—Ç", "–∞–∫—Ç—É–∞–ª—å", "—á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ", "—á—Ç–æ —Å–µ–π—á–∞—Å",
        "—Å–≤–µ–∂", "google", "–ø–æ–≥—É–≥–ª–∏", "–ø–æ–∏—Å–∫", "–Ω–∞–π–¥–∏",
        "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç", "—Ü–µ–Ω–∞", "–∫—É—Ä—Å", "—Å–µ–≥–æ–¥–Ω—è", "—Å–µ–π—á–∞—Å",
        "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ", "–∫–æ–≥–¥–∞ –≤—ã–π–¥–µ—Ç", "—Ä–µ–ª–∏–∑", "–æ–±–Ω–æ–≤–ª–µ–Ω"
    ]
    low = user_input.lower()
    if any(k in low for k in kw):
        return True

    # --- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —É—Ç–æ—á–Ω—è–µ–º —É LLM (—É–¥–æ—Ä–æ–∂–∞–µ—Ç –∑–∞–ø—Ä–æ—Å) ---
    # decision_prompt = (
    #     "–û–ø—Ä–µ–¥–µ–ª–∏, –Ω—É–∂–µ–Ω –ª–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫. –û—Ç–≤–µ—Ç—å —Ä–æ–≤–Ω–æ 'YES' –∏–ª–∏ 'NO'.\n"
    #     f"–ó–∞–ø—Ä–æ—Å: {user_input}"
    # )
    # try:
    #     decision = client.chat.completions.create(
    #         model=current_model,
    #         messages=[{"role": "user", "content": decision_prompt}],
    #         max_tokens=3
    #     ).choices[0].message.content.strip().upper()
    #     return decision == "YES"
    # except Exception:
    #     return False

    return False

def google_search(query: str, num_results: int = 5) -> List[dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫: [{title, link, snippet}]
    –¢—Ä–µ–±—É—é—Ç—Å—è GOOGLE_CSE_API_KEY –∏ GOOGLE_CSE_CX –≤ .env
    """
    from dotenv import load_dotenv
    load_dotenv()
    api_key = os.getenv("GOOGLE_CSE_API_KEY")
    cx = os.getenv("GOOGLE_CSE_CX")
    if not api_key or not cx:
        raise RuntimeError("Google CSE –∫–ª—é—á–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã (GOOGLE_CSE_API_KEY / GOOGLE_CSE_CX).")

    url = "https://www.googleapis.com/customsearch/v1"
    params = {"key": api_key, "cx": cx, "q": query, "num": num_results}

    r = requests.get(url, params=params, timeout=15)
    r.raise_for_status()
    data = r.json()

    items = []
    for it in data.get("items", []):
        items.append({
            "title": it.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
            "link": it.get("link", ""),
            "snippet": it.get("snippet", "")
        })
    return items

def summarize_search_results(query: str, results: List[dict]) -> str:
    """
    –ö–æ—Ä–º–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ GPT –∏ –ø—Ä–æ—Å–∏–º —á–∏—Å—Ç–æ–µ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –±–µ–∑ –≤–æ–¥—ã + —Å—Å—ã–ª–∫–∏.
    """
    # –°–æ–±–µ—Ä—ë–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    lines = []
    for i, it in enumerate(results, 1):
        lines.append(f"{i}. {it['title']}\n{it['snippet']}\n{it['link']}")
    corpus = "\n\n".join(lines)

    system_prompt = (
        "–¢—ã –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –∏ –≤–µ–±-–∞–Ω–∞–ª–∏—Ç–∏–∫. –£ —Ç–µ–±—è –ù–ï–¢ –¥–æ—Å—Ç—É–ø–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç; "
        "–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Å–Ω–∏–ø–ø–µ—Ç—ã –∏ —Å—Å—ã–ª–∫–∏. "
        "–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ (3‚Äì6 –ø—É–Ω–∫—Ç–æ–≤), "
        "—É–±–µ—Ä–∏ —Ä–µ–∫–ª–∞–º—É, –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –≤–æ–¥—É, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã. "
        "–í –∫–æ–Ω—Ü–µ –¥–∞–π —Å–ø–∏—Å–æ–∫ 2‚Äì4 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –¥–ª—è —É–≥–ª—É–±–ª–µ–Ω–∏—è."
    )
    user_prompt = (
        f"–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}\n\n"
        f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ (–∑–∞–≥–æ–ª–æ–≤–æ–∫ / —Å–Ω–∏–ø–ø–µ—Ç / —Å—Å—ã–ª–∫–∞):\n\n{corpus}"
    )

    resp = client.chat.completions.create(
        model=current_model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.3
    )
    return resp.choices[0].message.content


# --------------------
# Handlers
# --------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user_id = update.effective_user.id
    base = "–ü—Ä–∏–≤–µ—Ç! –Ø Telegram-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç–µ–∫—Å—Ç–∞ –∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.\n\n"
    common_cmds = "–ö–æ–º–∞–Ω–¥—ã:\n/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n/help ‚Äî –ø–æ–º–æ—â—å"
    if is_admin(user_id):
        extra = "\n/model <name> ‚Äî —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å\n/quota ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ—Å—Ç–∞—Ç–æ–∫ –±—é–¥–∂–µ—Ç–∞ OpenAI API"
        await update.message.reply_text(base + common_cmds + extra)
    else:
        await update.message.reply_text(base + common_cmds)

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
         return
    user_id = update.effective_user.id
    base = "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n/help ‚Äî –ø–æ–º–æ—â—å"
    if is_admin(user_id):
        extra = "\n/model <name> ‚Äî —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å\n/quota ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ—Å—Ç–∞—Ç–æ–∫ –±—é–¥–∂–µ—Ç–∞ OpenAI API"
        await update.message.reply_text(base + extra)
    else:
        await update.message.reply_text(base)

async def set_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user_id = update.effective_user.id
    if not is_admin(user_id):
        await update.message.reply_text("üö´ –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —Å–º–µ–Ω—É –º–æ–¥–µ–ª–∏.")
        return
    
    global current_model
    if not context.args:
        await update.message.reply_text(
            f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {current_model}\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /model gpt-4o –∏–ª–∏ /model gpt-3.5-turbo"
        )
        return
    new_model = context.args[0].strip()
    current_model = new_model
    await update.message.reply_text(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {current_model}")

async def quota(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user_id = update.effective_user.id
    if not is_admin(user_id):
        await update.message.reply_text("üö´ –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —Å–º–µ–Ω—É –º–æ–¥–µ–ª–∏.")
        return
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Å—Ç–∞—Ç–æ–∫ —Å—Ä–µ–¥—Å—Ç–≤ –ø–æ API. –ú–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤."""
    try:
        headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
        r = requests.get(
            "https://api.openai.com/dashboard/billing/credit_grants",
            headers=headers,
            timeout=10,
        )
        if r.status_code != 200:
            await update.message.reply_text(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–≤–æ—Ç—É (HTTP {r.status_code}): {r.text}"
            )
            return
        data = r.json()
        total = data.get("total_granted", 0.0)
        used = data.get("total_used", 0.0)
        remaining = data.get("total_available", 0.0)
        await update.message.reply_text(
            f"üí∞ –ë–∞–ª–∞–Ω—Å OpenAI API:\n"
            f"‚Äî –í—ã–¥–∞–Ω–æ: ${total:.2f}\n"
            f"‚Äî –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: ${used:.2f}\n"
            f"‚Äî –û—Å—Ç–∞—Ç–æ–∫: ${remaining:.2f}"
        )
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–≤–æ—Ç—ã: {format_exc(e)}")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return

    message = update.message
    chat = update.effective_chat
    user = update.effective_user
    user_id = user.id

    raw_text = message.text or ""
    user_input = raw_text.replace(f"@{BOT_USERNAME}", "").strip()

    logging.info(f"[{user.id}] @{user.username or 'no_username'} - TEXT: {user_input}")

    # –ë–∞–∑–∞ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π –≤ OpenAI
    messages = []

    # 1) –ì–†–£–ü–ü–´: –µ—Å–ª–∏ —ç—Ç–æ reply –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞ ‚Äî –¥–æ–±–∞–≤–∏–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–≤–µ—Ç –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if chat.type in ("group", "supergroup") and message.reply_to_message:
        reply_msg = message.reply_to_message
        if reply_msg.from_user and reply_msg.from_user.username == BOT_USERNAME:
            prev_text = reply_msg.text or ""
            if prev_text:
                messages.append({"role": "user", "content": prev_text})

    # 2) –ü–†–ò–í–ê–¢–ù–´–ï –ß–ê–¢–´: –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¢–û–õ–¨–ö–û –¥–ª—è –∞–¥–º–∏–Ω–æ–≤
    if chat.type == "private" and user_id in ADMINS:
        history = user_histories[user_id]
        # history —É–∂–µ deque(maxlen=10); –∫–æ–ø–∏—é –æ—Ç–¥–∞—ë–º –≤ GPT
        messages.extend(list(history))
        # –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —é–∑–µ—Ä—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å (–æ–¥–∏–Ω —Ä–∞–∑!)
        messages.append({"role": "user", "content": user_input})
    else:
        # –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏
        messages.append({"role": "user", "content": user_input})

    try:
        # 3) –£–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ: –Ω—É–∂–µ–Ω –ª–∏ –≤–µ–±-–ø–æ–∏—Å–∫
        if should_web_search(user_input):
            results = google_search(user_input, num_results=5)
            if results:
                summary = summarize_search_results(user_input, results)
                answer_text = summary
            else:
                answer_text = "–ù–∏—á–µ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –Ω–µ –Ω–∞—à—ë–ª –ø–æ –∑–∞–ø—Ä–æ—Å—É."
        else:
            # –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç GPT (–±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞)
            resp = client.chat_completions.create(  # <= –µ—Å–ª–∏ —É —Ç–µ–±—è openai>=1.x, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ: client.chat.completions.create
                model=current_model,
                messages=messages
            )
            answer_text = resp.choices[0].message.content

        # 4) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        await message.reply_text(answer_text)

        # 5) –ï—Å–ª–∏ –ø—Ä–∏–≤–∞—Ç–∫–∞ —Å –∞–¥–º–∏–Ω–æ–º ‚Äî –¥–æ–ø–∏—Å—ã–≤–∞–µ–º –ò –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
        if chat.type == "private" and user_id in ADMINS:
            history = user_histories[user_id]
            # –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–≤–µ —Ä–µ–ø–ª–∏–∫–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é: user + assistant
            # (user —É–∂–µ –¥–æ–±–∞–≤–∏–ª–∏ –≤—ã—à–µ, –¥–æ–±–∞–≤–∏–º assistant)
            history.append({"role": "assistant", "content": answer_text})

    except Exception as e:
        logging.exception("handle_text error")
        await message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {format_exc(e)}")


async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user = update.effective_user
    logging.info(f"[{user.id}] @{user.username or 'no_username'} - VOICE: –ø–æ–ª—É—á–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
    try:
        voice_file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as f:
            await voice_file.download_to_drive(f.name)
            ogg_path = f.name

        wav_path = ogg_path.replace(".ogg", ".wav")
        AudioSegment.from_ogg(ogg_path).export(wav_path, format="wav")

        # –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å (Whisper)
        with open(wav_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
            )
        text = transcript.text
        logging.info(f"{user} - VOICE TEXT: {text}")

        # –û—Ç–≤–µ—á–∞–µ–º LLM-–æ–º
        resp = client.chat.completions.create(
            model=current_model,
            messages=[{"role": "user", "content": text}],
        )
        await update.message.reply_text(
            f"üó£Ô∏è –¢—ã —Å–∫–∞–∑–∞–ª: {text}\n\nü§ñ {resp.choices[0].message.content}"
        )
    except Exception as e:
        logging.error(f"{user} - VOICE ERROR: {str(e)}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ: {format_exc(e)}")

async def handle_unsupported(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not is_allowed(update):
        return
    user = update.effective_user
    kind = type(update.message.effective_attachment)
    caption = update.message.caption or "(–±–µ–∑ –ø–æ–¥–ø–∏—Å–∏)"

    logging.info(f"[{user.id}] @{user.username or 'no_username'} - UNSUPPORTED: {kind} - Caption: {caption}")
    await update.message.reply_text("‚ùå –ò–∑–≤–∏–Ω–∏—Ç–µ, —è –ø–æ–∫–∞ –Ω–µ —É–º–µ—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ñ–∞–π–ª—ã, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤–ª–æ–∂–µ–Ω–∏—è.")

async def search_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args:
        await update.message.reply_text("‚ö†Ô∏è –£–∫–∞–∂–∏ –∑–∞–ø—Ä–æ—Å: /search <—Ç–µ–∫—Å—Ç>")
        return
    
    query = " ".join(context.args)
    try:
        results = google_search(query)
        if not results:
            await update.message.reply_text("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            return
        
        reply_text = "\n\n".join(results)
        await update.message.reply_text(reply_text)
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")

async def debug_log(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        logging.info("RAW UPDATE: %s", update.to_dict())
    except Exception as e:
        logging.exception("Failed to log raw update: %s", e)

async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if update.effective_chat.type == "private":
        user_histories.pop(user_id, None)
        await update.message.reply_text("üßπ –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω.")

# --------------------
# Main
# --------------------
def main():
    init_env()
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    # –ö–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("model", set_model))
    app.add_handler(CommandHandler("quota", quota))
    app.add_handler(CommandHandler("reset", reset))
    app.add_handler(CommandHandler("search", search_cmd))

    # –°–æ–æ–±—â–µ–Ω–∏—è
    #app.add_handler(MessageHandler(filters.ALL, debug_log), group=0)
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.PHOTO | Document.ALL | filters.VIDEO, handle_unsupported))

 

    logging.info(f"GPT-–±–æ—Ç –∑–∞–ø—É—â–µ–Ω! –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {current_model}")
    app.run_polling()
    me = app.bot.get_me()
    logging.info("Bot username:", me.username)

if __name__ == "__main__":
    main()
