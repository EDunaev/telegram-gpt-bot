#!/usr/bin/env python3
import os
import tempfile
import requests
import logging
from datetime import datetime
from pydub import AudioSegment
from dotenv import load_dotenv
from openai import OpenAI
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)
from telegram.ext.filters import Document

# --------------------
# Env & clients
# --------------------
load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DEFAULT_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")  # –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ .env

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise RuntimeError("TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω—ã –≤ .env")

client = OpenAI(api_key=OPENAI_API_KEY)
current_model = DEFAULT_MODEL  # –±—É–¥–µ—Ç –∏–∑–º–µ–Ω—è—Ç—å—Å—è –∫–æ–º–∞–Ω–¥–æ–π /model
logging.basicConfig(
    filename="bot.log",
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

# --------------------
# Helpers
# --------------------
def format_exc(e: Exception) -> str:
    return f"{type(e).__name__}: {e}"

# --------------------
# Handlers
# --------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø Telegram-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç–µ–∫—Å—Ç–∞ –∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/model <name> ‚Äî —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å (gpt-4o, gpt-3.5-turbo, ...)\n"
        "/quota ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ—Å—Ç–∞—Ç–æ–∫ –±—é–¥–∂–µ—Ç–∞ OpenAI API\n"
        "/help ‚Äî –ø–æ–º–æ—â—å"
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n"
        "/model <name> ‚Äî —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: /model gpt-3.5-turbo)\n"
        "/quota ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ—Å—Ç–∞—Ç–æ–∫ –±—é–¥–∂–µ—Ç–∞ OpenAI API\n\n"
        "–ü—Ä–æ—Å—Ç–æ –ø—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —è –æ—Ç–≤–µ—á—É üôÇ"
    )

async def set_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global current_model
    if not context.args:
        await update.message.reply_text(
            f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {current_model}\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /model gpt-4o –∏–ª–∏ /model gpt-3.5-turbo"
        )
        return
    new_model = context.args[0].strip()
    current_model = new_model
    await update.message.reply_text(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {current_model}")

async def quota(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Å—Ç–∞—Ç–æ–∫ —Å—Ä–µ–¥—Å—Ç–≤ –ø–æ API. –ú–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤."""
    try:
        headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
        r = requests.get(
            "https://api.openai.com/dashboard/billing/credit_grants",
            headers=headers,
            timeout=10,
        )
        if r.status_code != 200:
            await update.message.reply_text(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–≤–æ—Ç—É (HTTP {r.status_code}): {r.text}"
            )
            return
        data = r.json()
        total = data.get("total_granted", 0.0)
        used = data.get("total_used", 0.0)
        remaining = data.get("total_available", 0.0)
        await update.message.reply_text(
            f"üí∞ –ë–∞–ª–∞–Ω—Å OpenAI API:\n"
            f"‚Äî –í—ã–¥–∞–Ω–æ: ${total:.2f}\n"
            f"‚Äî –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: ${used:.2f}\n"
            f"‚Äî –û—Å—Ç–∞—Ç–æ–∫: ${remaining:.2f}"
        )
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–≤–æ—Ç—ã: {format_exc(e)}")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text
    user = update.effective_user

    logging.info(f"[{user.id}] @{user.username or 'no_username'} - TEXT: {user_input}")
    try:
        resp = client.chat.completions.create(
            model=current_model,
            messages=[{"role": "user", "content": user_input}],
        )
        await update.message.reply_text(resp.choices[0].message.content)
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {format_exc(e)}")

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    logging.info(f"[{user.id}] @{user.username or 'no_username'} - VOICE: –ø–æ–ª—É—á–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
    try:
        voice_file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as f:
            await voice_file.download_to_drive(f.name)
            ogg_path = f.name

        wav_path = ogg_path.replace(".ogg", ".wav")
        AudioSegment.from_ogg(ogg_path).export(wav_path, format="wav")

        # –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å (Whisper)
        with open(wav_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
            )
        text = transcript.text
        logging.info(f"{user} - VOICE TEXT: {text}")

        # –û—Ç–≤–µ—á–∞–µ–º LLM-–æ–º
        resp = client.chat.completions.create(
            model=current_model,
            messages=[{"role": "user", "content": text}],
        )
        await update.message.reply_text(
            f"üó£Ô∏è –¢—ã —Å–∫–∞–∑–∞–ª: {text}\n\nü§ñ {resp.choices[0].message.content}"
        )
    except Exception as e:
        logging.error(f"{user} - VOICE ERROR: {str(e)}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ: {format_exc(e)}")

async def handle_unsupported(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    kind = type(update.message.effective_attachment)

    logging.info(f"[{user.id}] @{user.username or 'no_username'} - UNSUPPORTED: {kind}")
    await update.message.reply_text("‚ùå –ò–∑–≤–∏–Ω–∏—Ç–µ, —è –ø–æ–∫–∞ –Ω–µ —É–º–µ—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ñ–∞–π–ª—ã, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤–ª–æ–∂–µ–Ω–∏—è.")


# --------------------
# Main
# --------------------
def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    # –ö–æ–º–∞–Ω–¥—ã
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("model", set_model))
    app.add_handler(CommandHandler("quota", quota))

    # –°–æ–æ–±—â–µ–Ω–∏—è
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.PHOTO | Document.ALL | filters.VIDEO | filters.VOICE, handle_unsupported))

    print(f"GPT-–±–æ—Ç –∑–∞–ø—É—â–µ–Ω! –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {current_model}")
    app.run_polling()

if __name__ == "__main__":
    main()
